{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mislabelled detection using self influence.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPorDVESkGJjvW7Wt4+bXTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praseedm/tracin_implemention_on_ledgar_dataset/blob/main/Mislabelled_detection_using_self_influence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE79mvzLFSYm",
        "outputId": "d63cee63-4387-4576-b9dd-97cc036f1526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tracin_implemention_on_ledgar_dataset'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 60 (delta 26), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (60/60), done.\n"
          ]
        }
      ],
      "source": [
        "# clone git repo for data\n",
        "! git clone https://github.com/praseedm/tracin_implemention_on_ledgar_dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9s8MqqNFcW8",
        "outputId": "b110a5f2-cd3c-4e9b-f210-6c21829cb70d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tracin_implemention_on_ledgar_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKI7AvRNH4GR",
        "outputId": "2058a895-382d-47a8-c239-ab5d5147b8e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tracin_implemention_on_ledgar_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfMbr8081jz1",
        "outputId": "6565a1ee-9e64-44a2-d0e8-d259c5ead647"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 37.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copying checkpoints \n",
        "!cp -r /content/drive/MyDrive/ARU/ML\\ Project/train_outputs ./"
      ],
      "metadata": {
        "id": "9Ia3CJmG0yly"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "OMkfxtfW0375"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1dQXQ2JK0_x9",
        "outputId": "b0588c59-2aad-4cd7-ef97-aff195540a1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "haNzkDGA1Ii3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "SEED = 10\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "VNtOsxtC1CNF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_dataset_from_csv(csv_path:str):\n",
        "  df = pd.read_csv(csv_path)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (\n",
        "          df['text'].values,\n",
        "          df['label'].values\n",
        "      )\n",
        "  )\n",
        "  print(f\"{len(dataset)}\\n{dataset.element_spec}\")\n",
        "  return dataset.batch(batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ehnnlyvt1L5r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = generate_batch_dataset_from_csv(csv_path='./data/train_data.csv')\n",
        "test_ds = generate_batch_dataset_from_csv(csv_path='./data/test_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLrWV9hk1NrS",
        "outputId": "678fbb4e-c874-4cfa-a1e0-fc0a61717d6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32906\n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
            "5438\n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "rOg9RU-u1Pks"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels \n",
        "with open('./data/label_names.json') as rb:\n",
        "  label_names = json.load(rb)\n",
        "print(f\"Loaded {len(label_names)} labels\")\n",
        "print(f\"Labels : {label_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQiMPgT1RUA",
        "outputId": "de56d0e4-32c2-4cc8-ecb6-c726799de216"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 25 labels\n",
            "Labels : ['Amendments', 'Assignments', 'Compliance With Laws', 'Confidentiality', 'Counterparts', 'Entire Agreements', 'Expenses', 'Financial Statements', 'Further Assurances', 'General', 'Governing Laws', 'Indemnifications', 'Insurances', 'Litigations', 'No Conflicts', 'Notices', 'Payments', 'Severability', 'Survival', 'Taxes', 'Terminations', 'Terms', 'Use Of Proceeds', 'Waiver Of Jury Trials', 'Waivers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load checkpoints"
      ],
      "metadata": {
        "id": "GARRL_lH1T68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints_root_dir = './train_outputs'\n",
        "def get_checkpoint_dir(epoch_number:int):\n",
        "  checkpoint_path = os.path.join(checkpoints_root_dir, f\"mymodel_{epoch_number}\")\n",
        "  if os.path.exists(checkpoint_path):\n",
        "    return checkpoint_path\n",
        "  raise ValueError(f\"{checkpoint_path} doesn't exists\")\n",
        "\n",
        "\n",
        "def load_model(model_path:str):\n",
        "  print(f\"Loading model from {model_path}\")\n",
        "  return tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "yjkAsD5M1S4k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load models\n",
        "checkpoint_models = []\n",
        "epochs = [2,4,5,6]\n",
        "for epoch in tqdm(epochs):\n",
        "  model_path = get_checkpoint_dir(epoch)\n",
        "  checkpoint_models.append(load_model(model_path=model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNhQ3M9x1aSy",
        "outputId": "bae29e93-4487-4687-d2cb-db1551d197b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 1/4 [00:11<00:35, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 2/4 [00:23<00:23, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 3/4 [00:35<00:12, 12.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:46<00:00, 11.70s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run self influence"
      ],
      "metadata": {
        "id": "sJI-MSG81tOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LYIVrOgN1r6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d1sjViAb1cDX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}