{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find_opponent_&_proponents.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBSXfNIL2c7xmwgAvqmQyT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praseedm/tracin_implemention_on_ledgar_dataset/blob/main/Find_opponent_%26_proponents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AjmFAF8mSgC",
        "outputId": "43a53db5-a581-4e28-b5cc-367e1187f9fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tracin_implemention_on_ledgar_dataset'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 54 (delta 22), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "# clone git repo for data\n",
        "! git clone https://github.com/praseedm/tracin_implemention_on_ledgar_dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbyCK5Cmkbn",
        "outputId": "f54aad28-de27-4a8c-fd73-287e912600ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tracin_implemention_on_ledgar_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obw6hLjWm-o1",
        "outputId": "6bd33f5d-5994-4e87-abff-1a4b4d4329b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tracin_implemention_on_ledgar_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copying checkpoints \n",
        "!cp -r /content/drive/MyDrive/ARU/ML\\ Project/train_outputs ./"
      ],
      "metadata": {
        "id": "gO3iNg-goaNx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg-4U_MJowiB",
        "outputId": "8645aa10-d92d-4dd0-b07b-148ef79ef297"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 61.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "bSRAxZ0uo9DF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLtWCexeo_6R",
        "outputId": "d68aa11e-1005-4e09-e143-5945d1f880c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dzwf9ZJNpCxv",
        "outputId": "71b33f75-222f-44d3-9bf9-6f2ffbba621c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "t4w_I1rTpdL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "SEED = 10\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "xabqROalpWxu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_dataset_from_csv(csv_path:str):\n",
        "  df = pd.read_csv(csv_path)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (\n",
        "          df['text'].values,\n",
        "          df['label'].values\n",
        "      )\n",
        "  )\n",
        "  print(f\"{len(dataset)}\\n{dataset.element_spec}\")\n",
        "  return dataset.batch(batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "LQfBAvuLpfSv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = generate_batch_dataset_from_csv(csv_path='./data/train_data.csv')\n",
        "test_ds = generate_batch_dataset_from_csv(csv_path='./data/test_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4E5G0tSpiSA",
        "outputId": "2ae8814a-861a-4f53-cca4-0af6ec9ab0ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32906\n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
            "5438\n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "3G-5iS73pmvD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels \n",
        "with open('./data/label_names.json') as rb:\n",
        "  label_names = json.load(rb)\n",
        "print(f\"Loaded {len(label_names)} labels\")\n",
        "print(f\"Labels : {label_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUCtAB4LpsAy",
        "outputId": "9e2b6673-0a58-48eb-dea6-24a07540ae03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 25 labels\n",
            "Labels : ['Amendments', 'Assignments', 'Compliance With Laws', 'Confidentiality', 'Counterparts', 'Entire Agreements', 'Expenses', 'Financial Statements', 'Further Assurances', 'General', 'Governing Laws', 'Indemnifications', 'Insurances', 'Litigations', 'No Conflicts', 'Notices', 'Payments', 'Severability', 'Survival', 'Taxes', 'Terminations', 'Terms', 'Use Of Proceeds', 'Waiver Of Jury Trials', 'Waivers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load checkpoints"
      ],
      "metadata": {
        "id": "lHmyuPZFy18i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints_root_dir = './train_outputs'\n",
        "def get_checkpoint_dir(epoch_number:int):\n",
        "  checkpoint_path = os.path.join(checkpoints_root_dir, f\"mymodel_{epoch_number}\")\n",
        "  if os.path.exists(checkpoint_path):\n",
        "    return checkpoint_path\n",
        "  raise ValueError(f\"{checkpoint_path} doesn't exists\")"
      ],
      "metadata": {
        "id": "YSgPGJf6y4pS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path:str):\n",
        "  print(f\"Loading model from {model_path}\")\n",
        "  return tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "70q9qP0Eyz6b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load models\n",
        "checkpoint_models = []\n",
        "epochs = [2,4,5,6]\n",
        "for epoch in tqdm(epochs):\n",
        "  model_path = get_checkpoint_dir(epoch)\n",
        "  checkpoint_models.append(load_model(model_path=model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_z3uVgs8_-7",
        "outputId": "4ab68c06-fdbd-471b-fe64-7fe379394df0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 1/4 [00:22<01:06, 22.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 2/4 [00:36<00:35, 17.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 3/4 [00:52<00:16, 16.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./train_outputs/mymodel_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [01:07<00:00, 17.00s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find proponents & Opponents"
      ],
      "metadata": {
        "id": "UVSYKifQ-Iv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_checkpoints(inputs, models):\n",
        "  texts, labels = inputs\n",
        "  loss_grads = []\n",
        "  for checkpoint_model in models:\n",
        "    logits = checkpoint_model(texts)\n",
        "    probs = tf.nn.softmax(logits)\n",
        "    loss_grad =  tf.one_hot(labels, len(label_names)) - probs\n",
        "    loss_grads.append(loss_grad)\n",
        "  \n",
        "  # prediction using last checkpoint\n",
        "  probs, predicted_labels =  tf.math.top_k(probs, k=1)\n",
        "\n",
        "  return texts, tf.stack(loss_grads, axis=-1), labels, probs, predicted_labels"
      ],
      "metadata": {
        "id": "5iML6tNR2hZ3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tracin_features(dataset):\n",
        "  texts = []\n",
        "  loss_grads = []\n",
        "  labels = []\n",
        "  predict_probs = []\n",
        "  predict_labels = []\n",
        "  \n",
        "  for batch in tqdm(dataset):\n",
        "    b_texts , b_loss_grads , b_labels, b_probs , b_predicted_labels = run_checkpoints(inputs=batch, models=checkpoint_models)\n",
        "    texts.append(b_texts.numpy())\n",
        "    loss_grads.append(b_loss_grads.numpy())\n",
        "    labels.append(b_labels.numpy())\n",
        "    predict_probs.append(b_probs.numpy())\n",
        "    predict_labels.append(b_predicted_labels.numpy())\n",
        "  \n",
        "  return {\n",
        "      'texts' : np.concatenate(texts),\n",
        "      'loss_grads' : np.concatenate(loss_grads),\n",
        "      'labels' : np.concatenate(labels),\n",
        "      'predicted_probs' : np.concatenate(predict_probs),\n",
        "      'predicted_labels' : np.concatenate(predict_labels)\n",
        "  }\n"
      ],
      "metadata": {
        "id": "Oqg9AprA2qsC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = generate_tracin_features(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efmlgyEXCiEX",
        "outputId": "ec681bef-03be-41a5-f5c6-334816bfd34c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:10<00:00, 10.24s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j5QPN_Iv64yi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}