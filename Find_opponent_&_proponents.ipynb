{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find_opponent_&_proponents.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtnC9JnBDX002t3y52szja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praseedm/tracin_implemention_on_ledgar_dataset/blob/main/Find_opponent_%26_proponents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AjmFAF8mSgC",
        "outputId": "3e32e6fc-92ca-4017-b182-1ebf82b4da23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tracin_implemention_on_ledgar_dataset'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 48 (delta 19), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "# clone git repo for data\n",
        "! git clone https://github.com/praseedm/tracin_implemention_on_ledgar_dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbyCK5Cmkbn",
        "outputId": "61b6c592-276f-46fc-bcfc-fa04aabc823c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tracin_implemention_on_ledgar_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obw6hLjWm-o1",
        "outputId": "a6d3d48a-b123-4d98-bfd8-48e558b9903a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tracin_implemention_on_ledgar_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copying checkpoints \n",
        "!cp -r /content/drive/MyDrive/ARU/ML\\ Project/train_outputs ./"
      ],
      "metadata": {
        "id": "gO3iNg-goaNx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg-4U_MJowiB",
        "outputId": "3ad4bc38-e392-42d9-c2de-01476dc3d659"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 46.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "bSRAxZ0uo9DF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLtWCexeo_6R",
        "outputId": "07af956d-e672-4ea7-94df-eccd6eb975b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 20:50:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dzwf9ZJNpCxv",
        "outputId": "c99a1da1-22ff-47d6-8d34-09f0eb27361f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "t4w_I1rTpdL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "SEED = 10\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "xabqROalpWxu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_dataset_from_csv(csv_path:str):\n",
        "  df = pd.read_csv(csv_path)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (\n",
        "          df['text'].values,\n",
        "          df['label'].values\n",
        "      )\n",
        "  )\n",
        "  print(f\"{len(dataset)}\\n{dataset.element_spec}\")\n",
        "  return dataset.batch(batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "LQfBAvuLpfSv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = generate_batch_dataset_from_csv(csv_path='./data/train_data.csv')\n",
        "test_ds = generate_batch_dataset_from_csv(csv_path='./data/test_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4E5G0tSpiSA",
        "outputId": "d860416c-e10c-4141-8d9b-ee1a91d23f6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32906\n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
            "5438\n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "3G-5iS73pmvD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels \n",
        "with open('./data/label_names.json') as rb:\n",
        "  label_names = json.load(rb)\n",
        "print(f\"Loaded {len(label_names)} labels\")\n",
        "print(f\"Labels : {label_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUCtAB4LpsAy",
        "outputId": "70bf9502-d11e-4a02-b3dc-7b8ddbf725d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 25 labels\n",
            "Labels : ['Amendments', 'Assignments', 'Compliance With Laws', 'Confidentiality', 'Counterparts', 'Entire Agreements', 'Expenses', 'Financial Statements', 'Further Assurances', 'General', 'Governing Laws', 'Indemnifications', 'Insurances', 'Litigations', 'No Conflicts', 'Notices', 'Payments', 'Severability', 'Survival', 'Taxes', 'Terminations', 'Terms', 'Use Of Proceeds', 'Waiver Of Jury Trials', 'Waivers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load checkpoints"
      ],
      "metadata": {
        "id": "lHmyuPZFy18i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints_root_dir = './train_outputs'\n",
        "def get_checkpoint_dir(epoch_number:int):\n",
        "  checkpoint_path = os.path.join(checkpoints_root_dir, f\"mymodel_{epoch_number}\")\n",
        "  if os.path.exists(checkpoint_path):\n",
        "    return checkpoint_path\n",
        "  raise ValueError(f\"{checkpoint_path} doesn't exists\")"
      ],
      "metadata": {
        "id": "YSgPGJf6y4pS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path:str):\n",
        "  print(f\"Loading model from {model_path}\")\n",
        "  return tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "70q9qP0Eyz6b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = tf.nn.softmax(model(tf.constant(['Except as otherwise set forth in this Debenture, the Company, for itself and its legal representatives, successors and assigns, expressly waiver'])))"
      ],
      "metadata": {
        "id": "LoU26iykzQAG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj6fQeUR0adq",
        "outputId": "ecda896e-b9e8-4b6f-c4f6-6d93b8022502"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
              "array([[2.2642531e-02, 2.1184969e-01, 3.1306303e-05, 9.8006327e-05,\n",
              "        2.3974039e-04, 1.6100150e-04, 1.1486170e-03, 8.8653956e-05,\n",
              "        7.4166362e-04, 3.2395215e-03, 4.8428634e-04, 3.1002457e-03,\n",
              "        4.6121114e-04, 3.1409060e-04, 9.2119008e-05, 1.1563308e-03,\n",
              "        1.2305392e-03, 1.6835412e-04, 2.8384614e-04, 1.0147768e-03,\n",
              "        5.6648382e-04, 6.9146411e-04, 1.2740496e-04, 4.2959419e-03,\n",
              "        7.4577212e-01]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F6PpHfpJ12gC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}